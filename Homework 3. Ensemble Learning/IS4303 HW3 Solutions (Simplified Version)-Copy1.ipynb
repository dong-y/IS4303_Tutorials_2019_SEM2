{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS4303 IT-MEDIATED FINANCIAL SOLUTIONS AND PLATFORMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Homework 3 - Tree and Ensemble Methods\n",
    "> ## Due Date: March 20 (Wed.), 2019, 23:00 SG Time\n",
    "> ## Name your `.ipynb` file as \"`StudentID_YourName_HW3.ipynb`\" and then upload \n",
    "> ## Please keep your results in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Python Version:</b> 2.7+<br>Create a virtual environment in Anaconda if needed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "<ul>\n",
    "    <li><a href=\"#0\" style=\"text-decoration: none\">0. Goal</a></li>\n",
    "    <li><a href=\"#1\" style=\"text-decoration: none\">1. Dataset</a></li>\n",
    "    <li><a href=\"#2\" style=\"text-decoration: none\">2. Data Preprocessing</a></li>\n",
    "    <li><a href=\"#3\" style=\"text-decoration: none\">3. Tree and Ensemble Learning</a></li>\n",
    "    <li><a href=\"#4\" style=\"text-decoration: none\">4. References</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Ensemble Learning Methods\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Resources:</b> \n",
    "<a href=\"https://en.wikipedia.org/wiki/Ensemble_learning\" target=\"_blank\" style=\"text-decoration: none\"><span class=\"label label-info\">Wikipedia</span></a>\n",
    "<a href=\"https://youtu.be/PGITM1E2CLk\" target=\"_blank\" style=\"text-decoration: none\"><span class=\"label label-warning\">Youtube</span></a>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/ensemble.html\" target=\"_blank\" style=\"text-decoration: none\"><span class=\"label label-danger\">Scikit-learn</span></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also watch this youtube video in this notebook\n",
    "from IPython.display import HTML, IFrame\n",
    "IFrame(src=\"https://www.youtube.com/embed/PGITM1E2CLk\", width=\"853\", height=\"480\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Goal\n",
    "\n",
    "* The goal of this assignment is to understand (1) Decision Tree (2) Ensemble Learning Methods (3) ROC and AUC.\n",
    "* In this assignment, we will clean data and build linear models using a lending dataset. \n",
    "* A dataset containing complete loan data for all loans issued has been uploaded on IVLE. It includes the current loan status (Current, Late, Fully Paid, etc.) and a large set of attributes for each customer. \n",
    "* The assignment will require you to use the dataset to build models to predict loan default.\n",
    "* Please answer the questions and write the code / results in the empty cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Dataset\n",
    "\n",
    "<br><div class=\"btn-group\"> \n",
    "    <a href=\"https://en.wikipedia.org/wiki/Lending_Club\" target=\"_blank\" class=\"btn btn-primary\" role=\"button\" style=\"text-decoration: none\">Introduction</a>\n",
    "    <a href=\"#overview\" class=\"btn btn-success\" role=\"button\" style=\"text-decoration: none\">Overview</a>\n",
    "    <a href=\"https://www.lendingclub.com/info/download-data.action\" target=\"_blank\" class=\"btn btn-info\" role=\"button\" style=\"text-decoration: none\">Attributes</a> \n",
    "    <a href=\"#task\" class=\"btn btn-warning\" role=\"button\" style=\"text-decoration: none\">Tasks</a>\n",
    "</div>\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "[LendingClub](https://en.wikipedia.org/wiki/Lending_Club) is a US peer-to-peer lending company, headquartered in San Francisco, California. It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. Lending Club is the world's largest peer-to-peer lending platform. The company claims that \\$15.98 billion in loans had been originated through its platform up to December 31, 2015.\n",
    "\n",
    "Lending Club enables borrowers to create unsecured personal loans between $\\text{\\$1,000}$ and $\\text{\\$40,000}$. The standard loan period is three years. Investors can search and browse the loan listings on Lending Club website and select loans that they want to invest in based on the information supplied about the borrower, amount of loan, loan grade, and loan purpose. Investors make money from interest. Lending Club makes money by charging borrowers an origination fee and investors a service fee.\n",
    "\n",
    "Lending Club also makes traditional direct to consumer loans, including automobile refinance transactions, through WebBank, an FDIC-insured, state-chartered industrial bank that is headquartered in Salt Lake City Utah. The loans are not funded by investors but are assigned to other financial institutions.\n",
    "\n",
    "In this homwork, we will use data from the Lending Club to predict whether the loan will default (along with prediction probabilities).\n",
    "\n",
    "<a id=\"overview\"></a>\n",
    "#### Overview\n",
    "The file <b>`LoanStats_2018Q{N}.csv`</b> contains complete loan data for all loans issued through the 2018 Quarter-{N}, including the current loan status (Current, Late, Fully Paid, etc.) and latest payment information. The file containing loan data through the \"present\" contains complete loan data for all loans issued through the previous completed calendar quarter. Additional features include credit scores, number of finance inquiries, address including zip codes, and state, and collections among others.  <br/>\n",
    "\n",
    "#### Attributes\n",
    "The dataset can be downloaded [here](https://www.lendingclub.com/info/download-data.action) and it has also been uploaded in the `Homework` folder on IVLE. Information on the columns and features can be found in data dictionary. A data dictionary is provided in a separate file <b>`LCDataDictionary.xlsx`</b>.\n",
    "\n",
    "<a id=\"task\"></a>\n",
    "#### Tasks: Data Cleaning, Pre-processing and Penalized Regression\n",
    "* The original dataset that you have downloaded has multiple attributes of each loan, along with an indicator of the `loan status`. \n",
    "* The status of the loan is 1 if the loan was “charged off” (CO), delinquent, or late in payment, and 0 otherwise. This is the outcome we are trying to predict in the analysis.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "* [Question 1](#Q1)\n",
    "* [Question 2](#Q2)\n",
    "* [Question 3](#Q3)\n",
    "* [Question 4](#Q4)\n",
    "* [Question 5](#Q5)\n",
    "* [Question 6](#Q6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/env python\n",
    "#-*- coding:utf-8 -*-\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt, log\n",
    "from functools import reduce, partial\n",
    "from collections import defaultdict\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Step 1: Read data into python pandas and named as \"loans\".</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "loan1 = pd.read_csv(\"./LoanStats_2018Q1.csv\", low_memory=False, header=1)\n",
    "loan2 = pd.read_csv(\"./LoanStats_2018Q2.csv\", low_memory=False, header=1)\n",
    "loan3 = pd.read_csv(\"./LoanStats_2018Q3.csv\", low_memory=False, header=1)\n",
    "\n",
    "# Append multiple datasets\n",
    "dataset = [loan1, loan2, loan3]\n",
    "loans = reduce(lambda left, right: pd.concat([left, right], ignore_index=True), dataset)\n",
    "loans.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Step 2: Delete rows when <code><b><i>loan_status</i></b></code> is \"Current\".</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = loans[loans['loan_status'] != 'Current']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Step 3: Create a new variable <code><b><i>bad_loans</i></b></code>: 1 means a risky (bad) loan, and 0 means a safe loan. A loan is risky when loan status is \"Charged Off\", \"Late (16-30 days)\", or \"Late (31-120 days)\", and the loan is safe when otherwise.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_status = ['Late (31-120 days)', 'Late (16-30 days)', 'Charged Off']\n",
    "loans['bad_loans'] = loans['loan_status'].map(lambda x: 1 if x in bad_status else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Step 4: Use a subset of numerical features.</b>\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Note:</b><p>Definitions of all columns are provided in a seperate file <b>LCDataDictionary.xlsx</b>.</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "loans_new = deepcopy(loans) # Please note the difference between shallow copy and deep copy in Python\n",
    "\n",
    "# We select 70 numerical features\n",
    "feature_full_list = ['acc_now_delinq','acc_open_past_24mths','all_util','annual_inc','avg_cur_bal','bc_open_to_buy','bc_util',\n",
    "                     'chargeoff_within_12_mths','collections_12_mths_ex_med','delinq_amnt','dti','inq_fi','inq_last_12m','inq_last_6mths',\n",
    "                     'installment','int_rate','last_pymnt_amnt','loan_amnt','max_bal_bc','mo_sin_old_il_acct','mo_sin_old_rev_tl_op',\n",
    "                     'mo_sin_rcnt_rev_tl_op','mo_sin_rcnt_tl','mort_acc','mths_since_last_delinq','mths_since_rcnt_il',\n",
    "                     'num_accts_ever_120_pd','num_actv_bc_tl','num_actv_rev_tl','num_bc_sats','num_bc_tl','num_il_tl','num_op_rev_tl',\n",
    "                     'num_rev_accts','num_rev_tl_bal_gt_0','num_sats','num_tl_30dpd','num_tl_90g_dpd_24m','num_tl_op_past_12m',\n",
    "                     'open_acc','open_acc_6m','open_act_il','open_il_12m','open_il_24m','open_rv_12m','open_rv_24m','out_prncp',\n",
    "                     'out_prncp_inv','pct_tl_nvr_dlq','percent_bc_gt_75','pub_rec_bankruptcies','revol_bal','revol_util','tax_liens',\n",
    "                     'tot_coll_amt','tot_cur_bal','tot_hi_cred_lim','total_acc','total_bal_ex_mort','total_bal_il','total_bc_limit',\n",
    "                     'total_cu_tl','total_il_high_credit_limit','total_pymnt','total_pymnt_inv','total_rec_int','total_rec_late_fee',\n",
    "                     'total_rec_prncp','total_rev_hi_lim','delinq_2yrs']\n",
    "output = 'bad_loans'\n",
    "loans_new = loans_new[feature_full_list+[output]]\n",
    "loans_new.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Step 5: Transform non-numerical features to numerical.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform object type to numerical type\n",
    "loans_new['int_rate'] = loans_new['int_rate'].str.rstrip('%').astype('float')\n",
    "loans_new['revol_util'] = loans_new['revol_util'].str.rstrip('%').astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Step 6: Drop Missing Values.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values and summary statistics\n",
    "loans_new.dropna(inplace=True)\n",
    "print(loans_new.shape)\n",
    "loans_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy \n",
    "from copy import deepcopy\n",
    "data = deepcopy(loans_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Tree and Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "\n",
    "# Read data\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Step 7: Train-Test Split</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "output = 'bad_loans'\n",
    "X = data.drop(output, axis=1) # Here no need to set inplace=True\n",
    "y = data[output]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "print(y_train.sum()/y_train.count(),y_test.sum()/y_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Question 1 (1 point): Decision Tree For Classification</b> \n",
    "<p>Please fit training data with <b>Classification Tree</b> model.</p>\n",
    "<p>Please report/print test accuracy on the <code><b>test</b></code> dataset.</p>\n",
    "<p><b>Remember: </b>Set <code><b>random_state=12345</b></code> so that results can be replicated.</p> \n",
    "<p>You can refer to: </p>\n",
    "<div class=\"btn-group\">    \n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\" target=\"_blank\" class=\"btn btn-primary\" role=\"button\" style=\"text-decoration: none\">Classification Tree</a>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on train data\n",
    "dtree = DecisionTreeClassifier(random_state=12345)\n",
    "dtree_model = dtree.fit(X_train, y_train)\n",
    "dtree_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels for test data\n",
    "y_pred_tree = dtree_model.predict(X_test)\n",
    "\n",
    "# Performance of model on test data\n",
    "print(\"Test Accuracy of Classificatioin Tree Model: \", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"Test Error of Classificatioin Tree Model: \", 1 - accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Question 2 (2 points): Ensemble Methods For Classification</b> \n",
    "<p>Please fit training data with <b>Bagging model</b>, <b>Random Forest model</b>, <b>AdaBoosting model</b> and <b>Gradient Boosting model</b>.</p>\n",
    "<p>Please report/print test accuracy scores of these 4 models on the <code><b>test</b></code> dataset.</p>\n",
    "<p><b>Remember: </b>Set <code><b>n_estimators=50</b></code> and <code><b>random_state=12345</b></code> so that results can be replicated.</p> \n",
    "<p>You can refer to: </p>\n",
    "<div class=\"btn-group\">    \n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\" target=\"_blank\" class=\"btn btn-primary\" role=\"button\" style=\"text-decoration: none\">Bagging</a>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" target=\"_blank\" class=\"btn btn-success\" role=\"button\" style=\"text-decoration: none\">Random Forest</a>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\" target=\"_blank\" class=\"btn btn-warning\" role=\"button\" style=\"text-decoration: none\">AdaBoost</a>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\" target=\"_blank\" class=\"btn btn-danger\" role=\"button\" style=\"text-decoration: none\">Gradient Boost</a>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of base learners\n",
    "N = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bag = BaggingClassifier(n_estimators=N, random_state=12345)\n",
    "Bag_model = Bag.fit(X_train, y_train)\n",
    "Bag_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels for test data\n",
    "y_pred_Bag = Bag_model.predict(X_test)\n",
    "\n",
    "# Performance of model on test data\n",
    "print(\"Test Accuracy of Bagging Model: \", accuracy_score(y_test, y_pred_Bag))\n",
    "print(\"Test Error of Bagging Model: \", 1 - accuracy_score(y_test, y_pred_Bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=N, random_state=12345)\n",
    "RF_model = RF.fit(X_train, y_train)\n",
    "RF_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels for test data\n",
    "y_pred_RF = RF_model.predict(X_test)\n",
    "\n",
    "# Performance of model on test data\n",
    "print(\"Test Accuracy of Random Forest Model: \", accuracy_score(y_test, y_pred_RF))\n",
    "print(\"Test Error of Random Forest Model: \", 1 - accuracy_score(y_test, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada = AdaBoostClassifier(n_estimators=N, random_state=12345)\n",
    "Ada_model = Ada.fit(X_train, y_train)\n",
    "Ada_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels for test data\n",
    "y_pred_Ada = Ada_model.predict(X_test)\n",
    "\n",
    "# Performance of model on test data\n",
    "print(\"Test Accuracy of Adaboosting Model: \", accuracy_score(y_test, y_pred_Ada))\n",
    "print(\"Test Error of Adaboosting Model: \", 1 - accuracy_score(y_test, y_pred_Ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier(n_estimators=N, random_state=12345)\n",
    "GB_model = GB.fit(X_train, y_train)\n",
    "GB_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels for test data\n",
    "y_pred_GB = GB_model.predict(X_test)\n",
    "\n",
    "# Performance of model on test data\n",
    "print(\"Test Accuracy of Gradient Boosting Model: \", accuracy_score(y_test, y_pred_GB))\n",
    "print(\"Test Error of Gradient Boosting Model: \", 1 - accuracy_score(y_test, y_pred_GB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Question 3 (3 points): Confusion Matrix, ROC and AUC</b> \n",
    "<p>Please print/report confusion matrix (i.e., true/false positive/negative) of the tree model in Question 1, and the 4 ensemble models in Question 2, on test data.</p>\n",
    "<p>Please plot ROC curves and report/print AUC values of the tree model in Question 1, and the 4 ensemble models in Question 2, on test data.</p>\n",
    "<p><b>Remember: </b>Set <code><b>n_estimators=50</b></code> and <code><b>random_state=12345</b></code> so that results can be replicated.</p> \n",
    "<p>You can refer to: </p>\n",
    "<div class=\"btn-group\"> \n",
    "    <a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\" target=\"_blank\" class=\"btn btn-success\" role=\"button\" style=\"text-decoration: none\">Performance Metrics</a>\n",
    "    <a href=\"https://matplotlib.org/users/pyplot_tutorial.html\" target=\"_blank\" class=\"btn btn-warning\" role=\"button\" style=\"text-decoration: none\">Matplotlib</a>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(model, features_train, output_train, features_test, output_test):\n",
    "    '''This function is used to calculate various model performance metrics.\n",
    "    Inputs:\n",
    "    1) model: The model you are using\n",
    "    2) features_train: The feature matrix of train data\n",
    "    3) output_train: The output label of train data\n",
    "    4) features_test: The feature matrix of test data\n",
    "    5) output_test: The output label of test data\n",
    "    \n",
    "    Outputs:\n",
    "    1) accuracy: Classification accuracy score\n",
    "    2) error: Classification error = 1 - accuracy\n",
    "    3) tp: True positive cases\n",
    "    4) fp: False positive cases\n",
    "    5) tn: True negative cases\n",
    "    6) fn: False negative cases\n",
    "    7) cm: Confusion matrix\n",
    "    8) sensitivity: True positive rate or Recall\n",
    "    9) specificity: True negative rate\n",
    "    10) precision: Positive predictive value\n",
    "    11) f1: F1 score\n",
    "    12) thresholds: Thresholds for Pr(y=1)\n",
    "    13) fpr: False positive rates\n",
    "    14) tpr: True positive rates\n",
    "    15) roc_auc: Area under curve of ROC   \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Fit the model:\n",
    "    model_fit = model.fit(features_train, output_train)\n",
    "\n",
    "    # Get predicted labels for test data\n",
    "    output_pred = model_fit.predict(features_test)\n",
    "\n",
    "    # Create performance metrics of test data\n",
    "    cm = confusion_matrix(output_test, output_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = accuracy_score(output_test, output_pred)\n",
    "    error = 1 - accuracy\n",
    "    sensitivity = recall_score(output_test, output_pred)\n",
    "    specificity = tn / (tn+fp)\n",
    "    precision = precision_score(output_test, output_pred)\n",
    "    f1 = f1_score(output_test, output_pred)    \n",
    "\n",
    "    # Get predicted scores Pr(y=1): Used as thresholds for calculating TP Rate and FP Rate\n",
    "    scores = model_fit.predict_proba(features_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(output_test, scores) # fpr: FP Rate, tpr: TP Rate, thresholds: Pr(y=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'error': error,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'confusion_matrix': cm,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'thresholds': thresholds,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'roc_auc': roc_auc        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models: tree, Bag, RF, Ada, GB\n",
    "models = [dtree, Bag, RF, Ada, GB]\n",
    "get_performance = partial(model_performance, features_train=X_train, output_train=y_train, features_test=X_test, output_test=y_test)\n",
    "dtree_performance, Bag_performance, RF_performance, Ada_performance, GB_performance = map(lambda x: get_performance(x), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Confusion Matrix:\n",
    "[tn, fp]\n",
    "[fn, tp]\n",
    "'''\n",
    "print(\"Confusion Matrix of Classification Tree Model: \\n {} \\n\".format(dtree_performance['confusion_matrix']))\n",
    "print(\"Confusion Matrix of Bagging Model: \\n {} \\n\".format(Bag_performance['confusion_matrix']))\n",
    "print(\"Confusion Matrix of Random Forest Model: \\n {} \\n\".format(RF_performance['confusion_matrix']))\n",
    "print(\"Confusion Matrix of AdaBoosting Model: \\n {} \\n\".format(Ada_performance['confusion_matrix']))\n",
    "print(\"Confusion Matrix of Gradient Boosting Model: \\n {} \\n\".format(GB_performance['confusion_matrix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of test data\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid(True)\n",
    "plt.plot(dtree_performance['fpr'], dtree_performance['tpr'], 'g-', label='ClassificationTree: AUC = %0.2f'% dtree_performance['roc_auc'])\n",
    "plt.plot(Bag_performance['fpr'], Bag_performance['tpr'], 'b*', label='Bagging: AUC = %0.2f'% Bag_performance['roc_auc'])\n",
    "plt.plot(RF_performance['fpr'], RF_performance['tpr'], 'y*-', label='RandomForest: AUC = %0.2f'% RF_performance['roc_auc'])\n",
    "plt.plot(Ada_performance['fpr'], Ada_performance['tpr'], 'm*', label='AdaBoosting: AUC = %0.2f'% Ada_performance['roc_auc'])\n",
    "plt.plot(GB_performance['fpr'], GB_performance['tpr'], 'k+', label='GradientBoosting: AUC = %0.2f'% GB_performance['roc_auc'])\n",
    "plt.plot([0,1], [0,1], 'r--', label='Reference Line')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.title('Receiver operating characteristic of models')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it more interactive\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "ensemble_performance = list(zip(['Tree','Bagging','RandomForest','Adaboost','GradientBoost'], \\\n",
    "                                [dtree_performance, Bag_performance, RF_performance, Ada_performance, GB_performance]))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Receiver operating characteristic of models',\n",
    "    xaxis = {\n",
    "        'title': 'False Positive Rate',\n",
    "        'range': [0, 1.1]\n",
    "    },\n",
    "    yaxis = {\n",
    "        'title': 'True Positive Rate',\n",
    "        'range': [0, 1.1]\n",
    "    }\n",
    ")\n",
    "\n",
    "trace_reference = go.Scatter(\n",
    "    x = [0, 1],\n",
    "    y = [0, 1],\n",
    "    mode = 'lines',\n",
    "    name = 'Reference Line',\n",
    "    line = {\n",
    "        'shape': 'spline',\n",
    "        'dash': 'dashdot',\n",
    "        'color': 'red',\n",
    "        'width': 2\n",
    "    }    \n",
    ")\n",
    "\n",
    "trace = [trace_reference]\n",
    "for item in ensemble_performance:\n",
    "    trace_roc = go.Scatter(\n",
    "        x = item[1]['fpr'],\n",
    "        y = item[1]['tpr'],\n",
    "        name = '%s: Accuracy=%f, AUC=%f' %(item[0], item[1]['accuracy'], item[1]['roc_auc']),\n",
    "    )\n",
    "    trace.append(trace_roc)\n",
    "\n",
    "fig = go.Figure(data=trace, layout=layout)\n",
    "py.offline.iplot(fig)                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Question 4 (2 points): Ensemble Methods and Model Performance</b> \n",
    "<p>Based on your results in Question 3, do you think that ensemble learning methods can improve model performance? If yes, why do you think so? What are the advantages of these ensemble methods.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Question 5 (3 points): Model Complexity And Performance</b> \n",
    "<p>Will model performance (e.g., accuracy, recall/sensitivity, precision, AUC, etc.) on test data be improved or not, if we increase the number of base learners of these 4 ensemble models? Is it always beneficial to increase the number of base learners? Write your arguments.</p>\n",
    "<p>Please also use visualization tools (e.g., plot/chart/diagram) to support your arguments.</p>\n",
    "<p><b>Remember: </b>Set <code><b>random_state=12345</b></code> so that results can be replicated.</p> \n",
    "<p>You can refer to: </p>\n",
    "<div class=\"btn-group\">    \n",
    "    <a href=\"https://matplotlib.org/users/pyplot_tutorial.html\" target=\"_blank\" class=\"btn btn-warning\" role=\"button\" style=\"text-decoration: none\">Matplotlib</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of base learners\n",
    "N_base = [5, 10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "# Performance Metrics\n",
    "metrics = ['accuracy','error', 'sensitivity', 'precision', 'roc_auc']\n",
    "\n",
    "# Initialize models\n",
    "models = {'Bagging': BaggingClassifier(random_state=12345),\n",
    "          'RandomForest': RandomForestClassifier(random_state=12345),\n",
    "          'AdaBoosting': AdaBoostClassifier(random_state=12345),\n",
    "          'GradientBoosting': GradientBoostingClassifier(random_state=12345)\n",
    "         }\n",
    "\n",
    "# Initialize performance metrics of different models with different number of base learners\n",
    "# metrics[Which_model][Which_metric]\n",
    "performance = defaultdict(lambda: defaultdict(lambda: []))\n",
    "\n",
    "# It will run for minutes. Please wait.\n",
    "for model_name in models.keys():\n",
    "    for n in N_base:\n",
    "        this_model = models[model_name].set_params(n_estimators=n)\n",
    "        pfm = model_performance(this_model, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            performance[model_name][metric].append(pfm[metric])     \n",
    "            \n",
    "def plot_performance(model_performance, performance_metric, base_learners):\n",
    "    '''This function is used to plot performance metrics with different number of base learners.\n",
    "    Inputs:\n",
    "    1) model_performance: A dictionary storing model performance metrics\n",
    "    2) performance_metric: Which performance metric to be plotted\n",
    "    3) base_learners: A list of base learner counts\n",
    "    \n",
    "    Outputs:\n",
    "    1) Plots of different performance metrics  \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(base_learners, model_performance['Bagging'][performance_metric], 'g-', \\\n",
    "             label='Bagging: %s' % performance_metric )\n",
    "    plt.plot(base_learners, model_performance['RandomForest'][performance_metric], 'r--', \\\n",
    "             label='RandomForest: %s' % performance_metric)\n",
    "    plt.plot(base_learners, model_performance['AdaBoosting'][performance_metric], 'm-o', \\\n",
    "             label='AdaBoosting: %s' % performance_metric)\n",
    "    plt.plot(base_learners, model_performance['GradientBoosting'][performance_metric], 'k-.', \\\n",
    "             label='GradientBoosting: %s' % performance_metric)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of base estimators')\n",
    "    plt.ylabel('%s' % performance_metric)\n",
    "    plt.title('%s on test data' % performance_metric)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()    \n",
    "    \n",
    "for metric in metrics:\n",
    "    plot_performance(performance, metric, N_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Question 6 (1 point): Limitations of Ensemble Methods</b> \n",
    "<p>Based on your knowledge, what are limitations/weakness/disadvantages of these ensemble methods (e.g., bagging, randomforest, gradientboost)? What may influence predictive power of these models?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open question:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
